{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import h5py\n",
    "from scipy.ndimage.interpolation import rotate\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import pymc3 as pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l</th>\n",
       "      <th>ENSG00000242268.2</th>\n",
       "      <th>ENSG00000270112.3</th>\n",
       "      <th>ENSG00000167578.15</th>\n",
       "      <th>ENSG00000273842.1</th>\n",
       "      <th>ENSG00000078237.5</th>\n",
       "      <th>ENSG00000146083.10</th>\n",
       "      <th>ENSG00000225275.4</th>\n",
       "      <th>ENSG00000158486.12</th>\n",
       "      <th>ENSG00000198242.12</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000088356.5</th>\n",
       "      <th>ENSG00000176752.6</th>\n",
       "      <th>ENSG00000223082.1</th>\n",
       "      <th>ENSG00000237714.1</th>\n",
       "      <th>ENSG00000200959.1</th>\n",
       "      <th>ENSG00000270971.2</th>\n",
       "      <th>ENSG00000267313.5</th>\n",
       "      <th>ENSG00000151632.15</th>\n",
       "      <th>ENSG00000269107.1</th>\n",
       "      <th>ENSG00000268889.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Luminal A</td>\n",
       "      <td>2356.253792</td>\n",
       "      <td>26808.891103</td>\n",
       "      <td>57790.161586</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71389.111749</td>\n",
       "      <td>381288.489078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1677.413295</td>\n",
       "      <td>1.969141e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>113036.499486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20911.752405</td>\n",
       "      <td>13957.784680</td>\n",
       "      <td>1.047700e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1937.768563</td>\n",
       "      <td>10731.974977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Luminal A</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>231.960840</td>\n",
       "      <td>115769.964478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77938.573803</td>\n",
       "      <td>238017.846096</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.865670e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>850405.301444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2122.068451</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5499.352680</td>\n",
       "      <td>2479.070667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Luminal A</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>315.873536</td>\n",
       "      <td>44954.933833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58546.997851</td>\n",
       "      <td>249302.406604</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.107768</td>\n",
       "      <td>2.519212e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>301948.579552</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>481.622432</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>312.031830</td>\n",
       "      <td>4822.690978</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Luminal A</td>\n",
       "      <td>1074.333108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>86991.783442</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36082.381881</td>\n",
       "      <td>176274.146728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.975469</td>\n",
       "      <td>2.855010e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>293581.147891</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12631.387770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Luminal A</td>\n",
       "      <td>1395.887715</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>65199.337535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91469.201926</td>\n",
       "      <td>263704.398926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.248682</td>\n",
       "      <td>4.235429e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>350449.557585</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1181.263740</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1626.418477</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1023 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               l  ENSG00000242268.2  ENSG00000270112.3  ENSG00000167578.15  \\\n",
       "0  Luminal A            2356.253792       26808.891103        57790.161586   \n",
       "1  Luminal A               0.000000         231.960840       115769.964478   \n",
       "2  Luminal A               0.000000         315.873536        44954.933833   \n",
       "3  Luminal A            1074.333108           0.000000        86991.783442   \n",
       "4  Luminal A            1395.887715           0.000000        65199.337535   \n",
       "\n",
       "   ENSG00000273842.1  ENSG00000078237.5  ENSG00000146083.10  \\\n",
       "0                0.0       71389.111749       381288.489078   \n",
       "1                0.0       77938.573803       238017.846096   \n",
       "2                0.0       58546.997851       249302.406604   \n",
       "3                0.0       36082.381881       176274.146728   \n",
       "4                0.0       91469.201926       263704.398926   \n",
       "\n",
       "   ENSG00000225275.4  ENSG00000158486.12  ENSG00000198242.12  ...  \\\n",
       "0                0.0         1677.413295        1.969141e+06  ...   \n",
       "1                0.0            0.000000        4.865670e+06  ...   \n",
       "2                0.0          270.107768        2.519212e+06  ...   \n",
       "3                0.0          101.975469        2.855010e+06  ...   \n",
       "4                0.0           66.248682        4.235429e+06  ...   \n",
       "\n",
       "   ENSG00000088356.5  ENSG00000176752.6  ENSG00000223082.1  ENSG00000237714.1  \\\n",
       "0      113036.499486                0.0       20911.752405       13957.784680   \n",
       "1      850405.301444                0.0           0.000000        2122.068451   \n",
       "2      301948.579552                0.0           0.000000         481.622432   \n",
       "3      293581.147891                0.0           0.000000           0.000000   \n",
       "4      350449.557585                0.0           0.000000        1181.263740   \n",
       "\n",
       "   ENSG00000200959.1  ENSG00000270971.2  ENSG00000267313.5  \\\n",
       "0       1.047700e+06                0.0        1937.768563   \n",
       "1       0.000000e+00                0.0        5499.352680   \n",
       "2       0.000000e+00                0.0         312.031830   \n",
       "3       0.000000e+00                0.0           0.000000   \n",
       "4       0.000000e+00                0.0           0.000000   \n",
       "\n",
       "   ENSG00000151632.15  ENSG00000269107.1  ENSG00000268889.1  \n",
       "0        10731.974977                0.0                0.0  \n",
       "1         2479.070667                0.0                0.0  \n",
       "2         4822.690978                0.0                0.0  \n",
       "3        12631.387770                0.0                0.0  \n",
       "4         1626.418477                0.0                0.0  \n",
       "\n",
       "[5 rows x 1023 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('dataset_LUMINAL_A_B.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1023)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENSG00000242268.2</th>\n",
       "      <th>ENSG00000270112.3</th>\n",
       "      <th>ENSG00000167578.15</th>\n",
       "      <th>ENSG00000273842.1</th>\n",
       "      <th>ENSG00000078237.5</th>\n",
       "      <th>ENSG00000146083.10</th>\n",
       "      <th>ENSG00000225275.4</th>\n",
       "      <th>ENSG00000158486.12</th>\n",
       "      <th>ENSG00000198242.12</th>\n",
       "      <th>ENSG00000259883.1</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000088356.5</th>\n",
       "      <th>ENSG00000176752.6</th>\n",
       "      <th>ENSG00000223082.1</th>\n",
       "      <th>ENSG00000237714.1</th>\n",
       "      <th>ENSG00000200959.1</th>\n",
       "      <th>ENSG00000270971.2</th>\n",
       "      <th>ENSG00000267313.5</th>\n",
       "      <th>ENSG00000151632.15</th>\n",
       "      <th>ENSG00000269107.1</th>\n",
       "      <th>ENSG00000268889.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2356.253792</td>\n",
       "      <td>26808.891103</td>\n",
       "      <td>57790.161586</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71389.111749</td>\n",
       "      <td>381288.489078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1677.413295</td>\n",
       "      <td>1.969141e+06</td>\n",
       "      <td>86793.265494</td>\n",
       "      <td>...</td>\n",
       "      <td>113036.499486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20911.752405</td>\n",
       "      <td>13957.784680</td>\n",
       "      <td>1.047700e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1937.768563</td>\n",
       "      <td>10731.974977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>231.960840</td>\n",
       "      <td>115769.964478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77938.573803</td>\n",
       "      <td>238017.846096</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.865670e+06</td>\n",
       "      <td>769.742944</td>\n",
       "      <td>...</td>\n",
       "      <td>850405.301444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2122.068451</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5499.352680</td>\n",
       "      <td>2479.070667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>315.873536</td>\n",
       "      <td>44954.933833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58546.997851</td>\n",
       "      <td>249302.406604</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.107768</td>\n",
       "      <td>2.519212e+06</td>\n",
       "      <td>2620.500780</td>\n",
       "      <td>...</td>\n",
       "      <td>301948.579552</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>481.622432</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>312.031830</td>\n",
       "      <td>4822.690978</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1074.333108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>86991.783442</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36082.381881</td>\n",
       "      <td>176274.146728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.975469</td>\n",
       "      <td>2.855010e+06</td>\n",
       "      <td>9893.339903</td>\n",
       "      <td>...</td>\n",
       "      <td>293581.147891</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12631.387770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1395.887715</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>65199.337535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91469.201926</td>\n",
       "      <td>263704.398926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.248682</td>\n",
       "      <td>4.235429e+06</td>\n",
       "      <td>2570.895661</td>\n",
       "      <td>...</td>\n",
       "      <td>350449.557585</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1181.263740</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1626.418477</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1022 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ENSG00000242268.2  ENSG00000270112.3  ENSG00000167578.15  \\\n",
       "0        2356.253792       26808.891103        57790.161586   \n",
       "1           0.000000         231.960840       115769.964478   \n",
       "2           0.000000         315.873536        44954.933833   \n",
       "3        1074.333108           0.000000        86991.783442   \n",
       "4        1395.887715           0.000000        65199.337535   \n",
       "\n",
       "   ENSG00000273842.1  ENSG00000078237.5  ENSG00000146083.10  \\\n",
       "0                0.0       71389.111749       381288.489078   \n",
       "1                0.0       77938.573803       238017.846096   \n",
       "2                0.0       58546.997851       249302.406604   \n",
       "3                0.0       36082.381881       176274.146728   \n",
       "4                0.0       91469.201926       263704.398926   \n",
       "\n",
       "   ENSG00000225275.4  ENSG00000158486.12  ENSG00000198242.12  \\\n",
       "0                0.0         1677.413295        1.969141e+06   \n",
       "1                0.0            0.000000        4.865670e+06   \n",
       "2                0.0          270.107768        2.519212e+06   \n",
       "3                0.0          101.975469        2.855010e+06   \n",
       "4                0.0           66.248682        4.235429e+06   \n",
       "\n",
       "   ENSG00000259883.1  ...  ENSG00000088356.5  ENSG00000176752.6  \\\n",
       "0       86793.265494  ...      113036.499486                0.0   \n",
       "1         769.742944  ...      850405.301444                0.0   \n",
       "2        2620.500780  ...      301948.579552                0.0   \n",
       "3        9893.339903  ...      293581.147891                0.0   \n",
       "4        2570.895661  ...      350449.557585                0.0   \n",
       "\n",
       "   ENSG00000223082.1  ENSG00000237714.1  ENSG00000200959.1  ENSG00000270971.2  \\\n",
       "0       20911.752405       13957.784680       1.047700e+06                0.0   \n",
       "1           0.000000        2122.068451       0.000000e+00                0.0   \n",
       "2           0.000000         481.622432       0.000000e+00                0.0   \n",
       "3           0.000000           0.000000       0.000000e+00                0.0   \n",
       "4           0.000000        1181.263740       0.000000e+00                0.0   \n",
       "\n",
       "   ENSG00000267313.5  ENSG00000151632.15  ENSG00000269107.1  ENSG00000268889.1  \n",
       "0        1937.768563        10731.974977                0.0                0.0  \n",
       "1        5499.352680         2479.070667                0.0                0.0  \n",
       "2         312.031830         4822.690978                0.0                0.0  \n",
       "3           0.000000        12631.387770                0.0                0.0  \n",
       "4           0.000000         1626.418477                0.0                0.0  \n",
       "\n",
       "[5 rows x 1022 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prendo tutto il data tranne prima colonna\n",
    "\n",
    "x = data.drop(data.columns[0], axis=1)\n",
    "x.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1022)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Luminal A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Luminal A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Luminal A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Luminal A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Luminal A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               l\n",
       "0  Luminal A    \n",
       "1  Luminal A    \n",
       "2  Luminal A    \n",
       "3  Luminal A    \n",
       "4  Luminal A    "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data['l']\n",
    "y = pd.DataFrame(y)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "l\n",
       "0    50\n",
       "1    50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y['l'])\n",
    "y['l'] = label_encoder.transform(y['l'])\n",
    "#vedere quante y sono 1 e quante 0\n",
    "y.groupby('l').size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# da pandas a numpy\n",
    "x = x.values\n",
    "y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1022)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the features with mean 0 and standard deviation 1\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "# scaler = MinMaxScaler()\n",
    "# zeta score\n",
    "scaler =  StandardScaler()\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rapporto tra autovalori e varianza totale: [2.36294301e-01 7.71203546e-02 4.60164724e-02 3.22558311e-02\n",
      " 2.87278810e-02 2.62773490e-02 2.29251505e-02 1.85951757e-02\n",
      " 1.80289934e-02 1.73597049e-02 1.63112951e-02 1.52491956e-02\n",
      " 1.44179954e-02 1.34794211e-02 1.30998818e-02 1.26489752e-02\n",
      " 1.21563927e-02 1.19418570e-02 1.16319089e-02 1.11206646e-02\n",
      " 1.08087430e-02 1.07205735e-02 1.01447634e-02 9.62813744e-03\n",
      " 9.52351003e-03 9.33201907e-03 9.19663679e-03 9.01224788e-03\n",
      " 8.93786194e-03 8.60569106e-03 8.44062687e-03 8.24618797e-03\n",
      " 8.03944117e-03 7.85016993e-03 7.62852936e-03 7.33762423e-03\n",
      " 7.29947273e-03 7.18312190e-03 6.99643073e-03 6.91051093e-03\n",
      " 6.76754582e-03 6.59093072e-03 6.35678449e-03 6.24057445e-03\n",
      " 6.15948554e-03 5.94542913e-03 5.76666133e-03 5.74269559e-03\n",
      " 5.50781489e-03 5.46174203e-03 5.41568096e-03 5.30054755e-03\n",
      " 5.12593696e-03 5.02449199e-03 4.83227783e-03 4.73485953e-03\n",
      " 4.64658500e-03 4.51119904e-03 4.47835678e-03 4.38470415e-03\n",
      " 4.34762639e-03 4.17338150e-03 4.10353520e-03 4.03440225e-03\n",
      " 3.88745638e-03 3.78520786e-03 3.68467519e-03 3.65621882e-03\n",
      " 3.56458798e-03 3.41205213e-03 3.29936586e-03 3.19721435e-03\n",
      " 3.10216785e-03 2.96881829e-03 2.92776329e-03 2.81872369e-03\n",
      " 2.40798062e-03 2.16254719e-03 1.97087006e-03 4.66008105e-32]\n",
      "Numero di componenti da mantenere: 37\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA  # Importa la classe PCA da scikit-learn\n",
    "import numpy as np  # Importa la libreria NumPy per la manipolazione dei dati\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Crea un oggetto PCA e adatta i dati\n",
    "pca = PCA()  # Crea un'istanza dell'oggetto PCA\n",
    "pca.fit(x_train_scaled)    # Adatta i dati di input (X) all'oggetto PCA per eseguire l'analisi delle componenti principali\n",
    "\n",
    "# Calcola gli autovalori e ordinali in ordine decrescente\n",
    "explained_variance = pca.explained_variance_  # Gli autovalori (varianza spiegata) in ordine\n",
    "explained_variance_ratio = pca.explained_variance_ratio_  # Rapporto tra gli autovalori e la varianza totale\n",
    "\n",
    "print(f\"Rapporto tra autovalori e varianza totale: {explained_variance_ratio}\")\n",
    "\n",
    "# Determina quante componenti mantenere (ad esempio, il 90% della varianza)\n",
    "desired_variance_ratio = 0.8  # Percentuale di varianza desiderata da mantenere\n",
    "cumulative_variance_ratio = np.cumsum(explained_variance_ratio)  # Calcola la varianza cumulativa\n",
    "num_components_to_keep = np.argmax(cumulative_variance_ratio >= desired_variance_ratio) + 1  # Trova il numero di componenti che soddisfano la percentuale desiderata\n",
    "\n",
    "# Stampa il numero di componenti da mantenere\n",
    "print(f\"Numero di componenti da mantenere: {num_components_to_keep}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca a x\n",
    "from sklearn.decomposition import PCA\n",
    "# pca = PCA(n_components=num_components_to_keep)# per mantenere il 90% della varianza delle feature iniziali\n",
    "pca = PCA(n_components=num_components_to_keep) \n",
    "\n",
    "x_train_pca = pca.fit_transform(x_train_scaled)\n",
    "x_test_pca = pca.transform(x_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_scaled = scaler.transform(x_train)\n",
    "# x_test_scaled = scaler.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 37)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 37)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tensor =  torch.from_numpy(x_train_pca).float()\n",
    "y_tensor =  torch.from_numpy(y_train).float()\n",
    "xtest_tensor =  torch.from_numpy(x_test_pca).float()\n",
    "ytest_tensor =  torch.from_numpy(y_test).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train set Tensors \n",
      "\n",
      "tensor([[-4.4387,  0.6071,  6.6695,  ..., -2.6065, -1.4676, -2.6911],\n",
      "        [-1.2546,  0.4565, -3.4425,  ..., -1.4324, -5.0529, -0.1509],\n",
      "        [-3.9780,  0.1327, -1.1133,  ...,  4.8125, -1.1409,  2.4224],\n",
      "        ...,\n",
      "        [-0.9286,  0.2960,  5.1233,  ...,  5.1272, -0.2867, -1.7629],\n",
      "        [-3.2873, -0.6129, -2.3093,  ..., -1.6876, -2.3325, -5.8457],\n",
      "        [-2.6369, -0.8528, -4.9192,  ..., -1.2411,  1.9540, -0.8159]])\n",
      "tensor([[1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "\n",
      "Test set Tensors \n",
      "\n",
      "tensor([[-2.5418e+00,  1.7110e+00, -2.2628e+00,  1.7218e+00, -3.3807e+00,\n",
      "         -2.0413e+00,  8.9743e+00, -7.6961e+00, -4.2837e+00,  1.3855e+00,\n",
      "         -5.0833e+00,  1.1490e+01,  1.0228e+01,  1.1398e+01, -6.1921e+00,\n",
      "          5.2122e+00,  1.1990e+01, -4.4846e+00, -3.8999e+00,  8.4842e+00,\n",
      "          8.0649e+00, -8.3964e-01, -5.0225e+00, -4.6384e+00,  5.7000e+00,\n",
      "         -7.7819e+00,  9.5443e+00, -3.4228e+00,  5.8686e+00, -3.5591e+00,\n",
      "          6.0179e-02,  2.1412e+00, -1.1675e+00,  1.0723e+00, -1.5567e-01,\n",
      "          9.4778e+00,  4.3933e+00],\n",
      "        [-5.0792e+00, -1.4472e+00, -1.7562e+00, -4.3462e+00,  3.6264e-01,\n",
      "         -1.0201e+00, -2.5034e+00, -2.3426e-01,  1.2694e-01, -5.7496e-01,\n",
      "         -2.8940e+00,  6.1523e-01,  7.9391e-01, -3.7729e+00, -1.8513e+00,\n",
      "         -1.2445e+00,  1.6511e+00, -2.7163e+00, -4.6703e+00,  5.6704e+00,\n",
      "          6.0631e-02, -7.4367e-01, -1.5562e+00, -7.4410e+00,  7.6229e+00,\n",
      "          1.6689e-01,  3.2101e+00,  2.4462e+00,  8.5077e+00,  1.0042e+00,\n",
      "          4.7539e-01,  3.5013e+00, -2.0097e-01, -1.5623e+00,  3.7947e+00,\n",
      "         -1.6535e-01, -2.2882e+00],\n",
      "        [-7.4556e-01, -1.0654e+00, -4.4241e+00, -1.8291e+00, -1.7194e+00,\n",
      "         -1.5460e+00,  7.6376e-01, -5.6509e-02,  1.2673e+00, -1.6131e+00,\n",
      "          2.3331e+00,  1.6594e+00,  7.9510e-01,  3.0540e-01,  3.2298e-01,\n",
      "          3.6552e-01,  4.2080e-01,  2.3889e-01,  7.5720e-01, -1.4602e-01,\n",
      "         -2.0206e-01, -7.5464e-01, -3.9935e-01, -1.3876e+00, -4.2632e-01,\n",
      "         -7.1762e-01, -9.4168e-01,  6.9556e-01, -4.6565e-01, -4.5748e-01,\n",
      "          3.2541e-02, -1.1390e-01,  1.1253e+00,  4.8571e-01, -2.1855e+00,\n",
      "          7.1160e-01, -1.1316e-01],\n",
      "        [-3.4983e+00,  6.1390e-01,  7.6922e+00,  4.6673e-01,  1.4203e+00,\n",
      "         -1.6124e-01, -2.7789e+00,  1.7698e+00,  4.4787e-01,  4.0760e+00,\n",
      "         -3.9413e+00, -1.7243e+00, -1.8314e+00,  6.4716e-01, -1.0375e+00,\n",
      "          2.2997e+00, -7.0744e-01, -1.8698e-01, -1.4272e+00, -4.7684e-01,\n",
      "          1.4744e+00,  2.5410e+00, -1.6191e+00,  5.6039e+00,  1.9957e+00,\n",
      "         -4.2560e-01, -2.9900e+00, -7.9738e-01,  1.7560e+00, -4.5972e-01,\n",
      "          3.3937e-01,  4.3826e-01,  5.6888e+00, -1.6956e+00, -1.1764e-01,\n",
      "          2.6872e-01,  2.3077e+00],\n",
      "        [-2.4310e+00, -8.1591e-02, -2.0590e+00, -2.2042e+00, -3.1731e-01,\n",
      "         -7.5526e-01, -2.2621e+00,  1.5095e+00, -1.4770e+00,  1.9195e+00,\n",
      "          2.4988e+00,  4.5963e-01,  4.1687e-01,  3.3157e+00, -2.2159e+00,\n",
      "         -4.2506e-02, -1.7350e+00, -2.1042e+00, -1.3054e+00,  1.6597e+00,\n",
      "          1.9726e+00,  2.0481e+00, -7.5319e-01, -3.2526e+00,  4.7384e-01,\n",
      "          2.6211e-01,  8.4106e-02,  2.7070e-01,  9.7745e-01, -3.3060e-02,\n",
      "          2.9606e-01, -2.2464e+00, -6.3877e-01, -2.0884e+00, -3.2401e+00,\n",
      "         -1.1126e+00,  1.1474e+00],\n",
      "        [-3.3930e+00,  5.1875e-01, -1.0250e-01,  3.6029e+00,  4.8381e-01,\n",
      "         -3.3313e+00, -4.0353e+00, -1.8519e+00,  4.4609e+00, -2.3735e+00,\n",
      "         -4.8981e-01, -1.0355e+00,  3.9471e+00, -8.6467e-01,  6.7930e+00,\n",
      "         -5.0388e+00,  8.2800e+00,  1.9183e+00,  4.1724e+00, -3.7952e+00,\n",
      "         -4.3189e-01, -3.2523e+00, -3.7677e+00,  3.5510e-01,  5.4944e+00,\n",
      "          2.4520e+00,  1.7468e+00, -4.4180e+00, -2.4546e-01, -3.8426e+00,\n",
      "          1.3587e-01, -3.7398e+00, -2.1055e+00,  2.6850e+00, -2.1883e+00,\n",
      "         -3.6574e-01, -4.2367e-01],\n",
      "        [-2.4386e+00,  9.1422e-02,  1.1745e+00, -1.5554e+00, -2.8065e-01,\n",
      "          1.1311e+00,  1.0748e+00, -2.2154e+00, -1.8963e+00,  5.5226e-01,\n",
      "          1.8620e+00, -1.7610e+00,  2.9885e-01, -2.6630e+00,  6.4906e-01,\n",
      "         -1.3054e+00,  1.2462e+00,  5.0803e-01, -3.5833e-02,  1.2825e+00,\n",
      "         -3.8983e-02, -2.3131e-01,  1.6749e+00,  2.1942e-01, -5.1771e-01,\n",
      "         -4.7179e-01,  1.1319e-01, -7.4791e-01, -4.4487e-01, -1.1537e+00,\n",
      "         -7.6436e-01,  4.1170e-01, -5.9733e-01,  1.4896e-01,  5.5279e-01,\n",
      "         -2.3149e-01,  2.4435e-01],\n",
      "        [ 4.5380e-01, -2.2390e-01, -6.0360e+00,  5.7157e+00, -2.0277e+00,\n",
      "         -2.2540e+00, -4.4379e+00, -1.0740e+00,  3.1505e+00,  5.9798e-02,\n",
      "          8.0525e-01, -1.7894e+00,  2.1260e+00,  2.3445e+00, -5.9910e-01,\n",
      "         -2.6796e+00,  5.6737e-01, -2.6077e-01,  3.6382e+00, -4.5432e+00,\n",
      "          6.3131e-01, -2.1792e+00, -2.0772e+00,  4.8820e-01,  1.5779e-01,\n",
      "          9.5607e-01,  1.0034e+00, -8.4377e-01, -6.6898e-01, -8.0955e-01,\n",
      "          2.3788e+00, -3.0541e+00, -7.8168e-01,  2.0813e+00, -4.9984e-01,\n",
      "          1.7210e+00, -1.8467e+00],\n",
      "        [-3.4081e+00,  4.9005e-01, -2.7871e+00,  1.9984e+00, -1.1814e-01,\n",
      "         -3.5120e+00, -1.0784e+00,  9.5962e-01,  9.1061e-01,  1.9497e-01,\n",
      "          4.1958e-01,  2.2856e+00, -1.7525e-01, -5.2745e-01,  3.7974e-01,\n",
      "          6.3319e-02, -2.4534e+00, -1.3838e+00, -2.5451e-01,  5.6291e-01,\n",
      "          6.4917e-01, -4.0945e-01,  1.1922e+00, -2.8089e-01, -1.5771e+00,\n",
      "         -9.1550e-01,  2.0543e+00, -1.0986e+00, -1.1823e-01,  1.1570e+00,\n",
      "          1.3594e+00, -2.1603e-01,  1.6422e+00,  1.3713e-01,  2.3862e-03,\n",
      "          7.9026e-01,  1.7847e+00],\n",
      "        [-5.9996e-01, -1.2188e+00, -2.9424e+00, -3.6949e+00, -1.9424e+00,\n",
      "          2.2008e+00,  1.3339e+00,  1.8316e+00, -2.5688e+00, -8.0478e-01,\n",
      "          1.7996e+00,  1.4205e+00,  5.8438e-01,  5.2267e-02,  3.0768e-01,\n",
      "         -8.3053e-01, -1.0848e+00,  5.5550e-01,  2.5782e-01,  1.3010e+00,\n",
      "         -3.3258e-01, -4.5130e-01,  9.9059e-01, -6.4364e-01,  6.3222e-01,\n",
      "         -9.4367e-01, -1.9582e-01, -8.7385e-01, -2.2477e+00, -9.8611e-01,\n",
      "          9.0909e-01, -1.0134e+00,  4.0830e-01, -5.5528e-01, -8.7644e-01,\n",
      "         -2.5352e-01, -2.5141e-01],\n",
      "        [-7.2303e-01,  2.4731e-01, -1.1805e+00,  2.5219e+00, -8.3674e-01,\n",
      "         -3.3001e+00, -3.4881e-03, -1.0540e-01,  2.4867e-01,  1.4737e+00,\n",
      "          9.6761e-01, -2.5567e+00, -8.8488e-01,  3.1862e+00,  7.9272e-01,\n",
      "         -1.4473e+00,  1.1458e-01, -7.3817e-01, -5.7737e-01,  3.4543e+00,\n",
      "         -1.4315e+00,  6.1120e-02, -2.1130e+00, -7.0887e-01, -2.4347e+00,\n",
      "          3.3789e+00,  1.6899e+00, -1.3282e+00,  1.2289e+00, -9.8657e-01,\n",
      "         -1.6788e+00,  2.6491e-01, -7.1156e-01,  1.7640e-01, -1.5645e+00,\n",
      "         -7.1727e-01,  1.5419e-01],\n",
      "        [-4.9619e+00, -6.9420e-01, -6.8184e-02, -2.3890e+00,  1.1934e+00,\n",
      "         -4.8009e+00,  2.8125e+00, -4.2855e-01, -2.3230e-01,  4.8193e-01,\n",
      "          3.2991e+00,  1.9744e+00, -1.3300e+00,  1.7964e+00,  1.9730e-02,\n",
      "         -2.7556e-01, -1.8180e+00, -4.9286e-01,  2.3616e+00, -1.1054e+00,\n",
      "         -1.0633e+00,  8.3838e-01, -2.7807e-01,  3.8867e-01,  5.4616e-01,\n",
      "          2.7589e-02, -8.0011e-01, -1.1904e-01,  8.0272e-01,  1.4857e+00,\n",
      "         -9.3782e-01, -4.1926e-02, -2.1265e+00,  1.2792e-01, -1.4078e+00,\n",
      "         -7.6241e-01, -2.8402e-01],\n",
      "        [-6.7077e-01, -3.9155e-01,  1.8348e-01,  2.2646e+00, -1.0767e+00,\n",
      "         -2.0539e+00, -1.6423e+00, -8.7797e-01, -1.3100e-01,  5.4530e-01,\n",
      "          3.0224e+00,  5.5325e-01,  6.7560e-01,  2.2113e+00,  5.3948e-01,\n",
      "          1.1138e+00, -1.0272e+00,  3.7418e-01,  1.6173e+00, -1.0985e+00,\n",
      "         -4.3419e-01, -1.3571e+00,  8.1460e-01,  7.6608e-01, -5.1275e-01,\n",
      "         -9.5032e-01, -2.3511e-01, -9.3479e-02, -2.2070e-01,  1.3783e-01,\n",
      "         -1.6994e-01,  9.9427e-01, -3.5293e-01,  7.0151e-01,  1.4925e-01,\n",
      "         -4.3057e-01,  1.5951e+00],\n",
      "        [ 1.3001e+00,  1.0766e+00,  4.2205e+00,  5.9005e+00, -2.3435e+00,\n",
      "          6.6459e-01, -5.8682e+00, -3.6665e+00, -4.3280e-01,  1.2294e+00,\n",
      "          2.1000e-01, -4.1486e+00,  2.8377e+00,  2.4907e+00, -4.6843e+00,\n",
      "         -2.2701e+00, -1.5962e+00,  2.4547e-01,  3.6161e+00, -1.7627e+00,\n",
      "          2.5691e+00,  1.7124e+00, -2.6211e+00,  2.3542e+00,  5.6117e-01,\n",
      "          3.8776e-01,  2.0860e+00, -9.1204e-01, -1.2780e+00,  7.1479e-01,\n",
      "          2.0674e+00, -5.7735e-01, -1.4910e+00, -1.0987e+00, -9.0277e-01,\n",
      "          2.0816e+00,  6.9290e-01],\n",
      "        [-2.4620e+00, -2.5394e-01, -9.5124e-01,  9.0805e-01,  3.0926e-01,\n",
      "         -2.5721e+00, -1.2318e+00,  3.6073e-01, -4.5564e-01,  1.3030e+00,\n",
      "          1.6255e+00, -5.6623e-01, -7.4947e-01, -9.1131e-01, -2.7321e+00,\n",
      "          2.0254e-01, -1.9079e+00, -1.2385e+00, -1.0972e+00, -3.7763e-01,\n",
      "          1.4638e-01, -1.2116e+00,  2.2237e+00,  2.7775e+00, -1.7537e+00,\n",
      "          4.7187e-01,  1.8747e+00,  9.9804e-01, -1.5120e-01,  1.6838e+00,\n",
      "          1.9918e+00, -1.3960e+00,  1.8229e-01, -8.2590e-01, -3.6646e-01,\n",
      "          4.0178e-01,  1.6024e+00],\n",
      "        [-2.0080e+00, -8.0167e-01, -1.7895e+00,  1.3564e+00, -1.5045e-01,\n",
      "         -1.4658e+00, -2.1727e+00, -9.7587e-01,  1.0360e+00,  2.6865e+00,\n",
      "          8.4192e-01, -1.0575e+00, -5.9474e-01,  8.1072e-01, -1.0540e+00,\n",
      "         -3.8990e-01, -9.6620e-01, -2.5659e-01,  4.6342e-01, -1.3399e+00,\n",
      "          6.2579e-01, -3.8700e-01,  1.1819e+00,  6.5879e-01,  3.9857e-01,\n",
      "         -4.3725e-01,  2.3363e-01,  5.1888e-01, -2.0628e-01,  1.0221e+00,\n",
      "         -1.0977e+00, -1.2138e+00, -6.9152e-01,  3.7686e-02, -1.4105e+00,\n",
      "         -1.3780e+00,  4.7215e-01],\n",
      "        [-9.0163e-01, -9.8508e-01, -2.5498e+00,  3.5851e-01, -1.9041e+00,\n",
      "          4.0448e-01, -2.2383e+00, -1.3768e+00,  3.1756e-01,  1.3167e+00,\n",
      "          2.4844e+00, -3.0697e+00, -8.6232e-01,  1.3357e-01, -5.3345e-01,\n",
      "         -1.5590e+00,  1.2417e+00,  1.2574e+00, -1.0776e+00, -2.5142e+00,\n",
      "         -9.1864e-01, -2.2417e+00,  1.7586e+00,  1.4046e+00, -2.4929e-01,\n",
      "          1.2012e+00,  2.5798e+00, -3.3829e-02,  7.3668e-01,  1.7794e+00,\n",
      "         -6.2739e-01, -1.0597e+00, -1.7599e+00,  4.1603e-01, -1.7682e+00,\n",
      "          1.2856e+00,  8.7223e-01],\n",
      "        [-1.5970e+00,  1.2186e+00, -6.7627e+00, -4.2744e+00, -3.8106e-01,\n",
      "          1.5766e-01,  3.0040e+00,  8.6689e-01,  7.9365e-01, -2.9547e+00,\n",
      "         -8.8268e-02, -2.0991e+00,  8.5196e-01, -2.7619e-01, -7.7762e-01,\n",
      "         -6.6554e-01, -1.6446e+00, -2.8714e-01, -2.3148e+00, -4.3325e-01,\n",
      "         -7.8027e-01,  1.5279e+00,  1.6304e-01, -9.9349e-01,  1.7022e+00,\n",
      "         -3.1272e-01,  1.6101e-01,  4.2072e-02, -4.6729e-01,  1.0961e+00,\n",
      "         -2.4356e+00,  7.9166e-01,  2.3331e-01, -1.0100e+00,  3.0030e+00,\n",
      "          1.4741e+00,  7.6538e-01],\n",
      "        [-6.8502e-01, -4.7273e-01, -7.9220e+00,  2.9492e+00, -2.3990e+00,\n",
      "         -1.1626e+00,  1.6051e-01,  4.2237e-01,  2.2945e+00, -9.8473e-01,\n",
      "         -8.9072e-01,  7.3561e-01,  4.3907e-01,  3.9089e-01,  9.6451e-01,\n",
      "         -1.8647e-01,  8.6855e-01,  6.0722e-01,  7.6805e-01, -1.5260e-01,\n",
      "          4.4875e-01, -2.0893e+00, -1.3715e+00, -7.7907e-01,  3.4141e-01,\n",
      "         -2.0388e-01, -4.5626e-01, -2.2362e+00, -2.4704e-01, -1.1734e-01,\n",
      "          2.3239e-01, -1.1990e+00,  6.1851e-01, -3.3332e-01, -1.2543e+00,\n",
      "         -7.9491e-02, -5.9442e-01],\n",
      "        [-5.2336e+00,  3.5706e-02,  1.4377e+00, -1.3900e+00,  2.6214e+00,\n",
      "          1.0137e+00, -1.9186e-01,  1.0150e+00, -3.3389e-01,  1.9619e+00,\n",
      "         -5.1428e+00, -3.2229e+00, -1.2935e+00,  4.2649e-01,  2.5458e+00,\n",
      "         -2.0579e+00,  6.0272e-01,  1.1072e+00, -5.3428e+00, -7.9350e-01,\n",
      "         -1.1418e+00,  5.6052e-01,  3.2991e+00,  1.1119e+00,  1.7523e+00,\n",
      "         -1.0389e+00, -8.2672e-01, -1.8663e+00,  8.5131e-01,  4.8678e-01,\n",
      "          1.0934e-01,  2.0542e+00,  2.4834e+00, -1.1770e+00,  4.5456e+00,\n",
      "         -4.9745e+00, -4.6866e-01]])\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.]])\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTrain set Tensors \\n\")\n",
    "print(x_tensor)\n",
    "print(y_tensor)\n",
    "print(\"\\nTest set Tensors \\n\")\n",
    "print(xtest_tensor)\n",
    "print(ytest_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([80, 37]) torch.Size([80, 1]) torch.Size([20, 37]) torch.Size([20, 1])\n"
     ]
    }
   ],
   "source": [
    "print(x_tensor.shape, y_tensor.shape, xtest_tensor.shape, ytest_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "#Both x_train and y_train can be combined in a single TensorDataset, which will be easier to iterate over and slice\n",
    "\n",
    "train_dataset = TensorDataset(x_tensor, y_tensor)\n",
    "test_dataset = TensorDataset(xtest_tensor, ytest_tensor)\n",
    "\n",
    "#Pytorch’s DataLoader is responsible for managing batches. \n",
    "#You can create a DataLoader from any Dataset. DataLoader makes it easier to iterate over batches\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP (Model)\n",
    "Define the Layers , Activation function , Number of nodes for the MultiLayerPerceptron\n",
    "\n",
    "#### Structure of MLP\n",
    "\n",
    "* 2 Hidden Layers\n",
    "* Normalizing the batch data usign batchnorm in between each layer\n",
    "* Using ReLU Activation function between the layers\n",
    "* Using dropout before sending to output\n",
    "* Sigmoid at the output layer to make probabilities between 0 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BayesianNN(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=37, out_features=500, bias=True)\n",
      "    (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=500, out_features=300, bias=True)\n",
      "    (5): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.5, inplace=False)\n",
      "    (8): Linear(in_features=300, out_features=1, bias=True)\n",
      "    (9): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "n_input = x_tensor.shape[1]\n",
    "\n",
    "n_hidden1 = 500\n",
    "n_hidden2 = 300\n",
    "n_output = 1 # 1 output neuron for binary classification with nn.BCELoss()\n",
    "# n_output = 2 # 2 output neuron for binary classification with nn.CrossEntropyLoss()\n",
    "\n",
    "class BayesianNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BayesianNN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "\n",
    "            nn.Linear(n_input, n_hidden1),\n",
    "            nn.BatchNorm1d(n_hidden1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(n_hidden1, n_hidden2),\n",
    "            nn.BatchNorm1d(n_hidden2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(n_hidden2, n_output),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "model = BayesianNN()\n",
    "print(model)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_acc(mlp: nn.Module, data_loader: torch.utils.data.DataLoader):\n",
    "  \n",
    "  correct = 0\n",
    "  total = 0\n",
    "  \n",
    "  with torch.no_grad():\n",
    "    for x, y in data_loader:\n",
    "      y_pred = model(x)\n",
    "      # print(y_pred)\n",
    "      y_pred_discr = torch.round(y_pred)\n",
    "      # print(y_pred_discr)\n",
    "      # print(y_pred.shape, y_pred_discr.shape, y.shape)\n",
    "      acc = torch.sum((y_pred_discr == y).float()) \n",
    "      correct += acc\n",
    "      total += y_pred.size(0)\n",
    "  \n",
    "  return correct/total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the MLP Model\n",
    "NN Steps flow\n",
    "\n",
    "* Forward Propagation\n",
    "* Loss computation\n",
    "* Backpropagation\n",
    "* Updating the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train accuracy: 0.5 test accuracy: 0.550000011920929\n",
      "Epoch: 1 \tTraining Loss: 0.618220\n",
      "Epoch 1 train accuracy: 0.675000011920929 test accuracy: 0.75\n",
      "Epoch: 2 \tTraining Loss: 0.500192\n",
      "Epoch 2 train accuracy: 0.824999988079071 test accuracy: 0.6499999761581421\n",
      "Epoch: 3 \tTraining Loss: 0.371012\n",
      "Epoch 3 train accuracy: 0.887499988079071 test accuracy: 0.699999988079071\n",
      "Epoch: 4 \tTraining Loss: 0.381956\n",
      "Epoch 4 train accuracy: 0.8999999761581421 test accuracy: 0.800000011920929\n",
      "Epoch: 5 \tTraining Loss: 0.425109\n",
      "Epoch 5 train accuracy: 0.887499988079071 test accuracy: 0.699999988079071\n",
      "Epoch: 6 \tTraining Loss: 0.350767\n",
      "Epoch 6 train accuracy: 0.9624999761581421 test accuracy: 0.800000011920929\n",
      "Epoch: 7 \tTraining Loss: 0.328714\n",
      "Epoch 7 train accuracy: 0.9125000238418579 test accuracy: 0.800000011920929\n",
      "Epoch: 8 \tTraining Loss: 0.128803\n",
      "Epoch 8 train accuracy: 0.925000011920929 test accuracy: 0.6499999761581421\n",
      "Epoch: 9 \tTraining Loss: 0.155863\n",
      "Epoch 9 train accuracy: 0.9125000238418579 test accuracy: 0.800000011920929\n",
      "Epoch: 10 \tTraining Loss: 0.210152\n",
      "Epoch 10 train accuracy: 0.949999988079071 test accuracy: 0.800000011920929\n",
      "Epoch: 11 \tTraining Loss: 0.135152\n",
      "Epoch 11 train accuracy: 0.9375 test accuracy: 0.800000011920929\n",
      "Epoch: 12 \tTraining Loss: 0.165666\n",
      "Epoch 12 train accuracy: 0.9375 test accuracy: 0.699999988079071\n",
      "Epoch: 13 \tTraining Loss: 0.108633\n",
      "Epoch 13 train accuracy: 0.9375 test accuracy: 0.6499999761581421\n",
      "Epoch: 14 \tTraining Loss: 0.152781\n",
      "Epoch 14 train accuracy: 0.949999988079071 test accuracy: 0.75\n",
      "Epoch: 15 \tTraining Loss: 0.130339\n",
      "Epoch 15 train accuracy: 0.949999988079071 test accuracy: 0.75\n",
      "Epoch: 16 \tTraining Loss: 0.077389\n",
      "Epoch 16 train accuracy: 0.9750000238418579 test accuracy: 0.699999988079071\n",
      "Epoch: 17 \tTraining Loss: 0.115125\n",
      "Epoch 17 train accuracy: 0.9750000238418579 test accuracy: 0.699999988079071\n",
      "Epoch: 18 \tTraining Loss: 0.233677\n",
      "Epoch 18 train accuracy: 0.9750000238418579 test accuracy: 0.699999988079071\n",
      "Epoch: 19 \tTraining Loss: 0.088656\n",
      "Epoch 19 train accuracy: 0.9624999761581421 test accuracy: 0.8500000238418579\n",
      "Epoch: 20 \tTraining Loss: 0.072381\n",
      "Epoch 20 train accuracy: 0.949999988079071 test accuracy: 0.699999988079071\n",
      "Epoch: 21 \tTraining Loss: 0.046132\n",
      "Epoch 21 train accuracy: 0.9750000238418579 test accuracy: 0.75\n",
      "Epoch: 22 \tTraining Loss: 0.046802\n",
      "Epoch 22 train accuracy: 0.949999988079071 test accuracy: 0.699999988079071\n",
      "Epoch: 23 \tTraining Loss: 0.034254\n",
      "Epoch 23 train accuracy: 0.987500011920929 test accuracy: 0.699999988079071\n",
      "Epoch: 24 \tTraining Loss: 0.019716\n",
      "Epoch 24 train accuracy: 0.987500011920929 test accuracy: 0.699999988079071\n",
      "Epoch: 25 \tTraining Loss: 0.066588\n",
      "Epoch 25 train accuracy: 0.987500011920929 test accuracy: 0.6499999761581421\n",
      "Epoch: 26 \tTraining Loss: 0.117708\n",
      "Epoch 26 train accuracy: 0.949999988079071 test accuracy: 0.75\n",
      "Epoch: 27 \tTraining Loss: 0.027502\n",
      "Epoch 27 train accuracy: 0.9624999761581421 test accuracy: 0.699999988079071\n",
      "Epoch: 28 \tTraining Loss: 0.061011\n",
      "Epoch 28 train accuracy: 0.987500011920929 test accuracy: 0.699999988079071\n",
      "Epoch: 29 \tTraining Loss: 0.104524\n",
      "Epoch 29 train accuracy: 0.987500011920929 test accuracy: 0.75\n",
      "Epoch: 30 \tTraining Loss: 0.064079\n",
      "Epoch 30 train accuracy: 0.987500011920929 test accuracy: 0.550000011920929\n",
      "Epoch: 31 \tTraining Loss: 0.116744\n",
      "Epoch 31 train accuracy: 0.987500011920929 test accuracy: 0.699999988079071\n",
      "Epoch: 32 \tTraining Loss: 0.240011\n",
      "Epoch 32 train accuracy: 0.987500011920929 test accuracy: 0.800000011920929\n",
      "Epoch: 33 \tTraining Loss: 0.028626\n",
      "Epoch 33 train accuracy: 1.0 test accuracy: 0.699999988079071\n",
      "Epoch: 34 \tTraining Loss: 0.445254\n",
      "Epoch 34 train accuracy: 0.9624999761581421 test accuracy: 0.6499999761581421\n",
      "Epoch: 35 \tTraining Loss: 0.015246\n",
      "Epoch 35 train accuracy: 0.987500011920929 test accuracy: 0.699999988079071\n",
      "Epoch: 36 \tTraining Loss: 0.077313\n",
      "Epoch 36 train accuracy: 0.987500011920929 test accuracy: 0.6499999761581421\n",
      "Epoch: 37 \tTraining Loss: 0.059708\n",
      "Epoch 37 train accuracy: 1.0 test accuracy: 0.75\n",
      "Epoch: 38 \tTraining Loss: 0.065600\n",
      "Epoch 38 train accuracy: 1.0 test accuracy: 0.6499999761581421\n",
      "Epoch: 39 \tTraining Loss: 0.039277\n",
      "Epoch 39 train accuracy: 0.987500011920929 test accuracy: 0.6499999761581421\n",
      "Epoch: 40 \tTraining Loss: 0.021105\n",
      "Epoch 40 train accuracy: 0.9750000238418579 test accuracy: 0.6000000238418579\n",
      "Epoch: 41 \tTraining Loss: 0.172858\n",
      "Epoch 41 train accuracy: 0.987500011920929 test accuracy: 0.699999988079071\n",
      "Epoch: 42 \tTraining Loss: 0.026069\n",
      "Epoch 42 train accuracy: 0.9750000238418579 test accuracy: 0.75\n",
      "Epoch: 43 \tTraining Loss: 0.042473\n",
      "Epoch 43 train accuracy: 0.987500011920929 test accuracy: 0.699999988079071\n",
      "Epoch: 44 \tTraining Loss: 0.039324\n",
      "Epoch 44 train accuracy: 0.949999988079071 test accuracy: 0.75\n",
      "Epoch: 45 \tTraining Loss: 0.017582\n",
      "Epoch 45 train accuracy: 1.0 test accuracy: 0.75\n",
      "Epoch: 46 \tTraining Loss: 0.029807\n",
      "Epoch 46 train accuracy: 0.987500011920929 test accuracy: 0.800000011920929\n",
      "Epoch: 47 \tTraining Loss: 0.036005\n",
      "Epoch 47 train accuracy: 0.987500011920929 test accuracy: 0.699999988079071\n",
      "Epoch: 48 \tTraining Loss: 0.176625\n",
      "Epoch 48 train accuracy: 1.0 test accuracy: 0.800000011920929\n",
      "Epoch: 49 \tTraining Loss: 0.026904\n",
      "Epoch 49 train accuracy: 1.0 test accuracy: 0.550000011920929\n",
      "Epoch: 50 \tTraining Loss: 0.050698\n",
      "Epoch 50 train accuracy: 0.987500011920929 test accuracy: 0.6499999761581421\n",
      "Epoch: 51 \tTraining Loss: 0.012571\n",
      "Epoch 51 train accuracy: 1.0 test accuracy: 0.75\n",
      "Epoch: 52 \tTraining Loss: 0.044964\n",
      "Epoch 52 train accuracy: 0.9750000238418579 test accuracy: 0.75\n",
      "Epoch: 53 \tTraining Loss: 0.012373\n",
      "Epoch 53 train accuracy: 1.0 test accuracy: 0.75\n",
      "Epoch: 54 \tTraining Loss: 0.038139\n",
      "Epoch 54 train accuracy: 0.987500011920929 test accuracy: 0.699999988079071\n",
      "Epoch: 55 \tTraining Loss: 0.006470\n",
      "Epoch 55 train accuracy: 1.0 test accuracy: 0.699999988079071\n",
      "Epoch: 56 \tTraining Loss: 0.076073\n",
      "Epoch 56 train accuracy: 0.987500011920929 test accuracy: 0.699999988079071\n",
      "Epoch: 57 \tTraining Loss: 0.011523\n",
      "Epoch 57 train accuracy: 1.0 test accuracy: 0.6499999761581421\n",
      "Epoch: 58 \tTraining Loss: 0.015145\n",
      "Epoch 58 train accuracy: 0.987500011920929 test accuracy: 0.699999988079071\n",
      "Epoch: 59 \tTraining Loss: 0.034478\n",
      "Epoch 59 train accuracy: 0.987500011920929 test accuracy: 0.75\n",
      "Epoch: 60 \tTraining Loss: 0.012872\n",
      "Epoch 60 train accuracy: 1.0 test accuracy: 0.699999988079071\n",
      "Epoch: 61 \tTraining Loss: 0.021632\n",
      "Epoch 61 train accuracy: 0.9750000238418579 test accuracy: 0.699999988079071\n",
      "Epoch: 62 \tTraining Loss: 0.007855\n",
      "Epoch 62 train accuracy: 0.987500011920929 test accuracy: 0.75\n",
      "Epoch: 63 \tTraining Loss: 0.034910\n",
      "Epoch 63 train accuracy: 1.0 test accuracy: 0.75\n",
      "Epoch: 64 \tTraining Loss: 0.045641\n",
      "Epoch 64 train accuracy: 1.0 test accuracy: 0.6000000238418579\n",
      "Epoch: 65 \tTraining Loss: 0.077506\n",
      "Epoch 65 train accuracy: 1.0 test accuracy: 0.800000011920929\n",
      "Epoch: 66 \tTraining Loss: 0.009078\n",
      "Epoch 66 train accuracy: 1.0 test accuracy: 0.8500000238418579\n",
      "Epoch: 67 \tTraining Loss: 0.005217\n",
      "Epoch 67 train accuracy: 0.9750000238418579 test accuracy: 0.699999988079071\n",
      "Epoch: 68 \tTraining Loss: 0.003663\n",
      "Epoch 68 train accuracy: 0.987500011920929 test accuracy: 0.75\n",
      "Epoch: 69 \tTraining Loss: 0.083776\n",
      "Epoch 69 train accuracy: 1.0 test accuracy: 0.6499999761581421\n",
      "Epoch: 70 \tTraining Loss: 0.020590\n",
      "Epoch 70 train accuracy: 1.0 test accuracy: 0.800000011920929\n",
      "Epoch: 71 \tTraining Loss: 0.014661\n",
      "Epoch 71 train accuracy: 0.9750000238418579 test accuracy: 0.6499999761581421\n",
      "Epoch: 72 \tTraining Loss: 0.008623\n",
      "Epoch 72 train accuracy: 1.0 test accuracy: 0.800000011920929\n",
      "Epoch: 73 \tTraining Loss: 0.002789\n",
      "Epoch 73 train accuracy: 1.0 test accuracy: 0.6499999761581421\n",
      "Epoch: 74 \tTraining Loss: 0.005900\n",
      "Epoch 74 train accuracy: 1.0 test accuracy: 0.699999988079071\n",
      "Epoch: 75 \tTraining Loss: 0.021556\n",
      "Epoch 75 train accuracy: 1.0 test accuracy: 0.75\n",
      "Epoch: 76 \tTraining Loss: 0.016063\n",
      "Epoch 76 train accuracy: 1.0 test accuracy: 0.75\n",
      "Epoch: 77 \tTraining Loss: 0.007208\n",
      "Epoch 77 train accuracy: 1.0 test accuracy: 0.6499999761581421\n",
      "Epoch: 78 \tTraining Loss: 0.022441\n",
      "Epoch 78 train accuracy: 1.0 test accuracy: 0.75\n",
      "Epoch: 79 \tTraining Loss: 0.019475\n",
      "Epoch 79 train accuracy: 0.987500011920929 test accuracy: 0.75\n",
      "Epoch: 80 \tTraining Loss: 0.076537\n",
      "Epoch 80 train accuracy: 1.0 test accuracy: 0.800000011920929\n",
      "Epoch: 81 \tTraining Loss: 0.037614\n",
      "Epoch 81 train accuracy: 0.9624999761581421 test accuracy: 0.75\n",
      "Epoch: 82 \tTraining Loss: 0.033591\n",
      "Epoch 82 train accuracy: 1.0 test accuracy: 0.800000011920929\n",
      "Epoch: 83 \tTraining Loss: 0.001223\n",
      "Epoch 83 train accuracy: 1.0 test accuracy: 0.800000011920929\n",
      "Epoch: 84 \tTraining Loss: 0.006925\n",
      "Epoch 84 train accuracy: 1.0 test accuracy: 0.800000011920929\n",
      "Epoch: 85 \tTraining Loss: 0.004285\n",
      "Epoch 85 train accuracy: 1.0 test accuracy: 0.75\n",
      "Epoch: 86 \tTraining Loss: 0.023516\n",
      "Epoch 86 train accuracy: 1.0 test accuracy: 0.75\n",
      "Epoch: 87 \tTraining Loss: 0.003393\n",
      "Epoch 87 train accuracy: 1.0 test accuracy: 0.6499999761581421\n",
      "Epoch: 88 \tTraining Loss: 0.013635\n",
      "Epoch 88 train accuracy: 1.0 test accuracy: 0.699999988079071\n",
      "Epoch: 89 \tTraining Loss: 0.010712\n",
      "Epoch 89 train accuracy: 1.0 test accuracy: 0.800000011920929\n",
      "Epoch: 90 \tTraining Loss: 0.004030\n",
      "Epoch 90 train accuracy: 1.0 test accuracy: 0.6499999761581421\n",
      "Epoch: 91 \tTraining Loss: 0.012127\n",
      "Epoch 91 train accuracy: 1.0 test accuracy: 0.6499999761581421\n",
      "Epoch: 92 \tTraining Loss: 0.008724\n",
      "Epoch 92 train accuracy: 1.0 test accuracy: 0.75\n",
      "Epoch: 93 \tTraining Loss: 0.029778\n",
      "Epoch 93 train accuracy: 0.987500011920929 test accuracy: 0.8500000238418579\n",
      "Epoch: 94 \tTraining Loss: 0.002778\n",
      "Epoch 94 train accuracy: 1.0 test accuracy: 0.75\n",
      "Epoch: 95 \tTraining Loss: 0.007452\n",
      "Epoch 95 train accuracy: 1.0 test accuracy: 0.6499999761581421\n",
      "Epoch: 96 \tTraining Loss: 0.018530\n",
      "Epoch 96 train accuracy: 0.987500011920929 test accuracy: 0.6499999761581421\n",
      "Epoch: 97 \tTraining Loss: 0.003095\n",
      "Epoch 97 train accuracy: 1.0 test accuracy: 0.6499999761581421\n",
      "Epoch: 98 \tTraining Loss: 0.004338\n",
      "Epoch 98 train accuracy: 1.0 test accuracy: 0.75\n",
      "Epoch: 99 \tTraining Loss: 0.002846\n",
      "Epoch 99 train accuracy: 1.0 test accuracy: 0.75\n",
      "Epoch: 100 \tTraining Loss: 0.001014\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "train_loss = []\n",
    "\n",
    "try:\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch} train accuracy: {eval_acc(model, train_loader)} \"\n",
    "                f\"test accuracy: {eval_acc(model, test_loader)}\")\n",
    "\n",
    "        #Within each epoch run the subsets of data = batch sizes.\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(x_batch)\n",
    "            # print(\"dim output nel train\", y_pred.shape, y_batch.shape)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        train_loss.append(loss.item())\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch+1, loss.item()))\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss)\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bioinfo_labs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
